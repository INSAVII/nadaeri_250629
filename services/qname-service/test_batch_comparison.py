#!/usr/bin/env python3
"""
ë°°ì¹˜ í¬ê¸°ë³„ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
"""

import pandas as pd
import time
from datetime import datetime
from processor import OptimizedQNameProcessor, check_api_keys

def create_test_file(count=20):
    """í…ŒìŠ¤íŠ¸ìš© ì—‘ì…€ íŒŒì¼ ìƒì„±"""
    test_data = {
        'ìƒí’ˆì½”ë“œ': [f'TEST{i:03d}' for i in range(1, count + 1)],
        'ë©”ì¸í‚¤ì›Œë“œ': [
            'í…€ë¸”ëŸ¬', 'ì»¤í”¼ì”', 'ë³´ì˜¨ë³‘', 'ì‹ê¸°ì„¸íŠ¸', 'ê·¸ë¦‡',
            'ìº í•‘ìš©í’ˆ', 'ì²­ì†Œë„êµ¬', 'ì •ë¦¬í•¨', 'ë³´ê´€ìš©í’ˆ', 'ì£¼ë°©ìš©í’ˆ',
            'ì»¤í”¼ë¨¸ì‹ ', 'ë¯¹ì„œê¸°', 'í† ìŠ¤í„°', 'ì „ìë ˆì¸ì§€', 'ì‹ê¸°ì„¸ì²™ê¸°',
            'ëƒ‰ì¥ê³ ', 'ê°€ìŠ¤ë ˆì¸ì§€', 'ì˜¤ë¸', 'ì—ì–´í”„ë¼ì´ì–´', 'ë¸”ë Œë”'
        ][:count]
    }
    
    df = pd.DataFrame(test_data)
    test_file = f"test_batch_{count}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    df.to_excel(test_file, index=False)
    print(f"í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±: {test_file} ({count}ê°œ í‚¤ì›Œë“œ)")
    return test_file

def test_batch_performance(batch_size, max_concurrent, test_file):
    """íŠ¹ì • ë°°ì¹˜ í¬ê¸°ë¡œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print(f"\n=== ë°°ì¹˜ í¬ê¸° {batch_size}, ë™ì‹œ ìš”ì²­ {max_concurrent} í…ŒìŠ¤íŠ¸ ===")
    
    # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    processor = OptimizedQNameProcessor(batch_size=batch_size, max_concurrent=max_concurrent)
    
    # ì²˜ë¦¬ ì‹œì‘
    start_time = time.time()
    print(f"ì²˜ë¦¬ ì‹œì‘: {datetime.now().isoformat()}")
    
    try:
        result = processor.process_excel_file(test_file)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        print(f"ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"ì„±ê³µ ì—¬ë¶€: {result['success']}")
        print(f"ì´ ì²˜ë¦¬ ìˆ˜: {result['total_processed']}")
        print(f"ì„±ê³µ ìˆ˜: {result['success_count']}")
        print(f"ì‹¤íŒ¨ ìˆ˜: {result['error_count']}")
        
        if result['success']:
            print(f"ì¶œë ¥ íŒŒì¼: {result['output_file']}")
        
        return {
            'batch_size': batch_size,
            'max_concurrent': max_concurrent,
            'total_time': total_time,
            'success': result['success'],
            'total_processed': result['total_processed'],
            'success_count': result['success_count'],
            'error_count': result['error_count']
        }
        
    except Exception as e:
        print(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def compare_batch_sizes():
    """ë°°ì¹˜ í¬ê¸°ë³„ ì„±ëŠ¥ ë¹„êµ"""
    print("=== ë°°ì¹˜ í¬ê¸°ë³„ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ===")
    
    # API í‚¤ í™•ì¸
    api_status = check_api_keys()
    print(f"API í‚¤ ìƒíƒœ: {api_status}")
    
    # 20ê°œ í‚¤ì›Œë“œë¡œ í…ŒìŠ¤íŠ¸
    test_file = create_test_file(20)
    
    # ë‹¤ì–‘í•œ ë°°ì¹˜ í¬ê¸°ë¡œ í…ŒìŠ¤íŠ¸
    test_configs = [
        (5, 3),   # ë°°ì¹˜ 5ê°œ, ë™ì‹œ ìš”ì²­ 3ê°œ
        (10, 5),  # ë°°ì¹˜ 10ê°œ, ë™ì‹œ ìš”ì²­ 5ê°œ
        (20, 8),  # ë°°ì¹˜ 20ê°œ, ë™ì‹œ ìš”ì²­ 8ê°œ
    ]
    
    results = []
    
    for batch_size, max_concurrent in test_configs:
        result = test_batch_performance(batch_size, max_concurrent, test_file)
        if result:
            results.append(result)
    
    # ê²°ê³¼ ë¹„êµ
    print("\n" + "="*60)
    print("=== ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ===")
    print("="*60)
    
    for result in results:
        print(f"ë°°ì¹˜ {result['batch_size']}ê°œ, ë™ì‹œ {result['max_concurrent']}ê°œ:")
        print(f"  - ì²˜ë¦¬ ì‹œê°„: {result['total_time']:.2f}ì´ˆ")
        print(f"  - ì„±ê³µë¥ : {result['success_count']}/{result['total_processed']} ({result['success_count']/result['total_processed']*100:.1f}%)")
        print()
    
    # ìµœì  ì„¤ì • ì°¾ê¸°
    if results:
        best_result = min(results, key=lambda x: x['total_time'])
        print(f"ğŸ† ìµœì  ì„¤ì •: ë°°ì¹˜ {best_result['batch_size']}ê°œ, ë™ì‹œ {best_result['max_concurrent']}ê°œ")
        print(f"   ì²˜ë¦¬ ì‹œê°„: {best_result['total_time']:.2f}ì´ˆ")

if __name__ == "__main__":
    compare_batch_sizes() 